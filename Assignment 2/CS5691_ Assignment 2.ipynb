{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1a\n",
    "! gdown 1u_VR07Kee92JrhAGq3VeXFR28uoZgxCX\n",
    "! gdown 1IvZk4IvzHVnEWGFqKZoea_OoqEEagLPs\n",
    "! gdown 1UItAFItujkbAo_RMouBnzBOPZ2306J7K\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1b\n",
    "! gdown 1iAPQ4tZIN1b7p3InunX5KbFd_8xMczVP\n",
    "! gdown 1BJekqgyr8tf_q_c3RQyPSpZNUwh5Ojhs\n",
    "! gdown 1BGG5CgFE3WClWVQPj4NJe_4jcSJ5PatO\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18nytesvrVSgyEApS9HqDBmop6vp5Rx-s\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/train_data.csv\n",
      "100%|██████████████████████████████████████| 7.09M/7.09M [00:01<00:00, 5.10MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aHIU8LzMreWJyn6roXFFwUA9IIs4Rrmy\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/train_label.csv\n",
      "100%|██████████████████████████████████████| 87.5k/87.5k [00:00<00:00, 1.72MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1W0pGwuBlXZ8dnoZhvf8rOJD1zaG_8Htb\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/val_data.csv\n",
      "100%|██████████████████████████████████████| 2.02M/2.02M [00:00<00:00, 4.08MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1G5yg9ZF9Wtx5JiIVANISlwdgUBC_d5iP\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/val_label.csv\n",
      "100%|██████████████████████████████████████| 25.0k/25.0k [00:00<00:00, 1.43MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ppBq_NSdtbMO6OGCi0I9mXJd5kGH6n_F\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/test_data.csv\n",
      "100%|██████████████████████████████████████| 1.01M/1.01M [00:00<00:00, 4.14MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QmHYtmKFPLL-3TxMWKa5DI4bHcAq6e5A\n",
      "To: /Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/test_label.csv\n",
      "100%|██████████████████████████████████████| 12.5k/12.5k [00:00<00:00, 17.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2\n",
    "! gdown 18nytesvrVSgyEApS9HqDBmop6vp5Rx-s\n",
    "! gdown 1aHIU8LzMreWJyn6roXFFwUA9IIs4Rrmy\n",
    "! gdown 1W0pGwuBlXZ8dnoZhvf8rOJD1zaG_8Htb\n",
    "! gdown 1G5yg9ZF9Wtx5JiIVANISlwdgUBC_d5iP\n",
    "! gdown 1ppBq_NSdtbMO6OGCi0I9mXJd5kGH6n_F\n",
    "! gdown 1QmHYtmKFPLL-3TxMWKa5DI4bHcAq6e5A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, method, covariance_type = None):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        self.num_features = self.X_train.shape[1]\n",
    "\n",
    "        # common\n",
    "        self.num_classes = None\n",
    "        self.train_classes = None\n",
    "        self.val_classes = None\n",
    "        self.test_classes = None\n",
    "\n",
    "        # gaussian and gmm\n",
    "        self.mean = None\n",
    "        self.covariance = None\n",
    "\n",
    "        self.prior_probabilities = None\n",
    "\n",
    "        # gmm\n",
    "        self.num_components = None\n",
    "        self.covariance_type = covariance_type\n",
    "\n",
    "        self.responsibilities = None\n",
    "        self.component_probabilities = None\n",
    "        self.component_means = None\n",
    "        self.component_covariances = None\n",
    "\n",
    "        self.best_num_components = None\n",
    "        self.best_responsibilities = None\n",
    "        self.best_component_probabilities = None\n",
    "        self.best_component_means = None\n",
    "        self.best_component_covariances = None\n",
    "\n",
    "        self.init_classes()\n",
    "\n",
    "        if(method == \"knn\"):\n",
    "            pass\n",
    "        elif(method == \"gaussian\" or method == \"gmm\"):\n",
    "            self.init_gaussian()\n",
    "\n",
    "    \n",
    "    def gaussian_pdf(self, x, mean, covariance):\n",
    "        return (1 / np.sqrt(np.linalg.det(covariance))) * np.exp(-0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(covariance)), (x - mean)))\n",
    "    \n",
    "\n",
    "    def gaussian_pdf_vectorized(self, x, mean, covariance):\n",
    "        n = len(mean)\n",
    "        x_mean = x - mean\n",
    "        inv_cov = np.linalg.inv(covariance)\n",
    "        normalization = 1.0 / np.sqrt((2 * np.pi) ** n * np.linalg.det(covariance))\n",
    "        exponent = -0.5 * np.sum(x_mean.dot(inv_cov) * x_mean, axis=1)\n",
    "        pdf = normalization * np.exp(exponent)\n",
    "        return pdf\n",
    "    \n",
    "    \n",
    "    def init_classes(self):\n",
    "        unique_classes = np.unique(self.y_train)\n",
    "\n",
    "        self.num_classes = unique_classes.shape[0]\n",
    "\n",
    "        self.train_classes = {label: self.X_train[self.y_train == label] for label in unique_classes}\n",
    "        self.val_classes = {label: self.X_val[self.y_val == label] for label in unique_classes}\n",
    "        self.test_classes = {label: self.X_test[self.y_test == label] for label in unique_classes}\n",
    "\n",
    "        self.prior_probabilities = {label: (self.train_classes[label].shape[0] / self.X_train.shape[0]) for label in unique_classes}\n",
    "\n",
    "    def init_gaussian(self):\n",
    "        for i in range(self.num_classes):\n",
    "            self.mean = {label: np.mean(self.train_classes[label], axis=0) for label in self.train_classes}\n",
    "            self.covariance = {label: np.cov(self.train_classes[label].T) for label in self.train_classes}\n",
    "\n",
    "        \n",
    "    def init_gmm(self):\n",
    "        # K-means clustering to identify num_componenent clusters in each class\n",
    "        max_iters = 200\n",
    "\n",
    "        components = {}\n",
    "        for i in range(self.num_classes):\n",
    "            components[i] = {}\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            n = self.train_classes[i].shape[0]\n",
    "            centroids = self.train_classes[i][np.random.choice(n, self.num_components, replace=False)]\n",
    "\n",
    "            for _ in range(max_iters):\n",
    "                # Assign each data point to the nearest cluster\n",
    "                distances = np.linalg.norm(self.train_classes[i][:, np.newaxis] - centroids, axis=2)\n",
    "                labels = np.argmin(distances, axis=1)\n",
    "\n",
    "                # Update cluster centroids\n",
    "                new_centroids = np.array([self.train_classes[i][labels == k].mean(axis=0) if np.sum(labels == k) > 0 else centroids[k] for k in range(self.num_components)])\n",
    "\n",
    "                # Check for convergence\n",
    "                if np.all(new_centroids == centroids):\n",
    "                    break\n",
    "\n",
    "                centroids = new_centroids\n",
    "\n",
    "            # assign the samples to the clusters based on nearest centroid\n",
    "            distances = np.linalg.norm(self.train_classes[i][:, np.newaxis] - centroids, axis=2)\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "            for sample, label in zip(self.train_classes[i], labels):\n",
    "                if(label not in components[i]):\n",
    "                    components[i][label] = []\n",
    "                components[i][label].append(sample)\n",
    "\n",
    "            for label in components[i]:\n",
    "                components[i][label] = np.vstack(components[i][label])\n",
    "\n",
    "        # initialize the parameters of the GMM\n",
    "        self.component_means = {}\n",
    "        self.component_covariances = {}\n",
    "        self.component_probabilities = {}\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            self.component_means[i] = {}\n",
    "            self.component_covariances[i] = {}\n",
    "            self.component_probabilities[i] = {}\n",
    "\n",
    "            for label in components[i]:\n",
    "                self.component_means[i][label] = np.mean(components[i][label], axis=0)\n",
    "                self.component_covariances[i][label] = np.cov(components[i][label].T)\n",
    "                if(self.covariance_type == \"diagonal\"):\n",
    "                    self.component_covariances[i][label] = np.diag(np.diag(self.component_covariances[i][label]))\n",
    "                self.component_probabilities[i][label] = components[i][label].shape[0] / self.train_classes[i].shape[0]\n",
    "\n",
    "        self.responsibilities = {}\n",
    "        for i in range(self.num_classes):\n",
    "            self.responsibilities[i] = np.zeros((self.train_classes[i].shape[0], self.num_components))\n",
    "\n",
    "        # EM algorithm\n",
    "        max_iters = 200\n",
    "        for _ in range(max_iters):\n",
    "            # E-step\n",
    "            for i in range(self.num_classes):\n",
    "                for label in components[i]:\n",
    "                    self.responsibilities[i][:, label] = self.component_probabilities[i][label] * self.gaussian_pdf_vectorized(self.train_classes[i], self.component_means[i][label], self.component_covariances[i][label])\n",
    "                self.responsibilities[i] /= np.sum(self.responsibilities[i], axis=1, keepdims=True)\n",
    "\n",
    "            # M-step\n",
    "            for i in range(self.num_classes):\n",
    "                for label in components[i]:\n",
    "                    self.component_means[i][label] = np.sum(self.responsibilities[i][:, label][:, np.newaxis] * self.train_classes[i], axis=0) / np.sum(self.responsibilities[i][:, label])\n",
    "                    self.component_covariances[i][label] = np.dot((self.responsibilities[i][:, label][:, np.newaxis] * (self.train_classes[i] - self.component_means[i][label])).T, (self.train_classes[i] - self.component_means[i][label])) / np.sum(self.responsibilities[i][:, label])\n",
    "                    if(self.covariance_type == \"diagonal\"):\n",
    "                        self.component_covariances[i][label] = np.diag(np.diag(self.component_covariances[i][label]))\n",
    "                    self.component_probabilities[i][label] = np.sum(self.responsibilities[i][:, label]) / self.train_classes[i].shape[0]\n",
    "\n",
    "\n",
    "    def KNN_predict(self, K, origin):\n",
    "        prediction = None\n",
    "        prediction_radius = 1e9\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            distances = np.linalg.norm(self.train_classes[cls] - origin, axis=1)\n",
    "            K_nearest_neighbours = np.argsort(distances)[:K]\n",
    "            \n",
    "            smallest_radius = distances[K_nearest_neighbours[-1]]\n",
    "            if(prediction_radius > smallest_radius):\n",
    "                prediction = cls\n",
    "                prediction_radius = smallest_radius\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "    def KNN(self, K_list):\n",
    "        classification_accuracy = {\n",
    "            \"K\" : [],\n",
    "            \"Training Accuracy\" : [],\n",
    "            \"Validation Accuracy\" : [],\n",
    "            \"Testing Accuracy\" : [],\n",
    "        }\n",
    "\n",
    "        for K in K_list:\n",
    "            # plot the decision boundary if it is 2-dimensional input\n",
    "            if(self.num_features == 2):\n",
    "                x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
    "                y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
    "\n",
    "                X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "                X = np.c_[X1.ravel(), X2.ravel()]\n",
    "\n",
    "                Z = np.array([self.KNN_predict(K, x) for x in X])\n",
    "                Z = Z.reshape(X1.shape)\n",
    "\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                plt.contourf(X1, X2, Z, alpha=0.4)\n",
    "\n",
    "                for i in range(self.num_classes):\n",
    "                    plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
    "\n",
    "                plt.title(f\"KNN Decision Boundary for K = {K}\")\n",
    "                plt.xlabel(\"X1\")\n",
    "                plt.ylabel(\"X2\")\n",
    "                plt.legend()\n",
    "\n",
    "                plt.savefig(f\"Bayes Classifier using KNN with K = {K}.jpeg\", dpi=300, format=\"jpeg\")\n",
    "                plt.close()\n",
    "\n",
    "            # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_train, self.y_train):\n",
    "                prediction = self.KNN_predict(K, X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"KNN_Training_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_val, self.y_val):\n",
    "                prediction = self.KNN_predict(K, X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"KNN_Validation_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_test, self.y_test):\n",
    "                prediction = self.KNN_predict(K, X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"KNN_Testing Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            classification_accuracy[\"K\"].append(K)\n",
    "            classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
    "            classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
    "            classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
    "\n",
    "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
    "        accuracy_df.to_csv(\"KNN Accuracy.csv\", index=False)\n",
    "\n",
    "    \n",
    "    def gaussian_predict(self, x):\n",
    "        probabilities = np.zeros(self.num_classes)\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            probabilities[cls] = self.prior_probabilities[cls] * self.gaussian_pdf(x, self.mean[cls], self.covariance[cls])\n",
    "\n",
    "        return np.argmax(probabilities)\n",
    "    \n",
    "\n",
    "    def gaussian(self):\n",
    "        # plot the decision boundary and level curves if it is 2-dimensional input \n",
    "        if(self.num_features == 2):\n",
    "            x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
    "            y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
    "\n",
    "            X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "            Z = np.array([self.gaussian_predict(x) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
    "            Z = Z.reshape(X1.shape)\n",
    "\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.contourf(X1, X2, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "            for i in range(self.num_classes):\n",
    "                X1, X2 = np.meshgrid(np.linspace(self.mean[i][0] - 10, self.mean[i][0] + 10, 100), np.linspace(self.mean[i][1] - 10, self.mean[i][1] + 10, 100))\n",
    "                Z = np.array([self.gaussian_pdf(x, self.mean[i], self.covariance[i]) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
    "                Z = Z.reshape(X1.shape)\n",
    "                plt.contour(X1, X2, Z, colors=\"grey\", levels=20, alpha=0.7, linewidths=0.6)\n",
    "\n",
    "            for i in range(self.num_classes):\n",
    "                plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
    "\n",
    "            plt.title(f\"Gaussian Decision Boundary and Level Curves\")\n",
    "            plt.xlabel(\"X1\")\n",
    "            plt.ylabel(\"X2\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"Bayes Classifier using Gaussian.png\", dpi=300, format=\"png\")\n",
    "            plt.close()\n",
    "\n",
    "        classification_accuracy = {\n",
    "            \"Training Accuracy\" : [],\n",
    "            \"Validation Accuracy\" : [],\n",
    "            \"Testing Accuracy\" : [],\n",
    "        }\n",
    "\n",
    "        # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
    "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "        for X, y in zip(self.X_train, self.y_train):\n",
    "            prediction = self.gaussian_predict(X)\n",
    "            confusion_matrix[y, prediction] += 1\n",
    "        \n",
    "        training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "        np.savetxt(\"Gaussian_Training_Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "        for X, y in zip(self.X_val, self.y_val):\n",
    "            prediction = self.gaussian_predict(X)\n",
    "            confusion_matrix[y, prediction] += 1\n",
    "\n",
    "        validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "        np.savetxt(\"Gaussian_Validation_Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "        for X, y in zip(self.X_test, self.y_test):\n",
    "            prediction = self.gaussian_predict(X)\n",
    "            confusion_matrix[y, prediction] += 1\n",
    "\n",
    "        testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "        np.savetxt(\"Gaussian_Testing Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "        classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
    "        classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
    "        classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
    "\n",
    "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
    "        accuracy_df.to_csv(\"Gaussian Accuracy.csv\", index=False)\n",
    "\n",
    "    \n",
    "    def gmm_predict(self, x):\n",
    "        probabilities = np.zeros(self.num_classes)\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            for label in self.component_means[cls]:\n",
    "                probabilities[cls] += self.component_probabilities[cls][label] * self.gaussian_pdf(x, self.component_means[cls][label], self.component_covariances[cls][label])\n",
    "\n",
    "        return np.argmax(probabilities)\n",
    "    \n",
    "\n",
    "    def gmm(self, Q_list):\n",
    "        # plot the decision boundary and level curves if it is 2-dimensional input\n",
    "        classification_accuracy = {\n",
    "            \"Number of Components\" : [],\n",
    "            \"Training Accuracy\" : [],\n",
    "            \"Validation Accuracy\" : [],\n",
    "            \"Testing Accuracy\" : [],\n",
    "        }\n",
    "\n",
    "        best_val_accuracy = 0\n",
    "        for Q in Q_list:\n",
    "            self.num_components = Q\n",
    "            self.init_gmm()\n",
    "            if(self.num_features == 2):\n",
    "                x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
    "                y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
    "\n",
    "                X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "                Z = np.array([self.gmm_predict(x) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
    "                Z = Z.reshape(X1.shape)\n",
    "\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                plt.contourf(X1, X2, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "                for i in range(self.num_classes):\n",
    "                    for label in self.component_means[i]:\n",
    "                        X1, X2 = np.meshgrid(np.linspace(self.component_means[i][label][0] - 10, self.component_means[i][label][0] + 10, 100), np.linspace(self.component_means[i][label][1] - 10, self.component_means[i][label][1] + 10, 100))\n",
    "                        Z = np.array([self.gaussian_pdf(x, self.component_means[i][label], self.component_covariances[i][label]) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
    "                        Z = Z.reshape(X1.shape)\n",
    "                        plt.contour(X1, X2, Z, colors=\"grey\", levels=20, alpha=0.7, linewidths=0.6)\n",
    "\n",
    "                for i in range(self.num_classes):\n",
    "                    plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
    "\n",
    "                plt.title(f\"GMM Decision Boundary and Level Curves\\nQ={Q}\")\n",
    "                plt.xlabel(\"X1\")\n",
    "                plt.ylabel(\"X2\")\n",
    "                plt.legend()\n",
    "\n",
    "                plt.savefig(f\"Bayes Classifier using GMM(Q={Q}).png\", dpi=300, format=\"png\")\n",
    "                plt.close()\n",
    "\n",
    "            # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_train, self.y_train):\n",
    "                prediction = self.gmm_predict(X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"GMM_Training_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_val, self.y_val):\n",
    "                prediction = self.gmm_predict(X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"GMM_Validation_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
    "            for X, y in zip(self.X_test, self.y_test):\n",
    "                prediction = self.gmm_predict(X)\n",
    "                confusion_matrix[y, prediction] += 1\n",
    "\n",
    "            testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "            np.savetxt(f\"GMM_Testing_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
    "\n",
    "            if(best_val_accuracy < validation_accuracy):\n",
    "                best_val_accuracy = validation_accuracy\n",
    "                self.best_num_components = self.num_components\n",
    "                self.best_responsibilities = self.responsibilities\n",
    "                self.best_component_probabilities = self.component_probabilities\n",
    "                self.best_component_means = self.component_means\n",
    "                self.best_component_covariances = self.component_covariances\n",
    "\n",
    "            classification_accuracy[\"Number of Components\"].append(Q)\n",
    "            classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
    "            classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
    "            classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
    "\n",
    "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
    "        accuracy_df.to_csv(\"GMM Accuracy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./Train-20.csv\")\n",
    "val_df = pd.read_csv(\"./Val-20.csv\")\n",
    "test_df = pd.read_csv(\"./Test-20.csv\")\n",
    "\n",
    "train_data = train_df[[\"input1\", \"input2\"]]\n",
    "train_label = train_df[\"output\"].astype(int)\n",
    "\n",
    "val_data = val_df[[\"input1\", \"input2\"]]\n",
    "val_label = val_df[\"output\"].astype(int)\n",
    "\n",
    "test_data = test_df[[\"input1\", \"input2\"]]\n",
    "test_label = test_df[\"output\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
    "y_train = train_label.to_numpy()\n",
    "\n",
    "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
    "y_val = val_label.to_numpy()\n",
    "\n",
    "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
    "y_test = test_label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier using KNNs for estimation of class-conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_list = [10, 20]\n",
    "classifier.KNN(K_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./Train-10.csv\")\n",
    "val_df = pd.read_csv(\"./Val-10.csv\")\n",
    "test_df = pd.read_csv(\"./Test-10.csv\")\n",
    "\n",
    "train_data = train_df[[\"x1\", \"x2\"]]\n",
    "train_label = train_df[\"label\"].astype(int)\n",
    "\n",
    "val_data = val_df[[\"x1\", \"x2\"]]\n",
    "val_label = val_df[\"label\"].astype(int)\n",
    "\n",
    "test_data = test_df[[\"x1\", \"x2\"]]\n",
    "test_label = test_df[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
    "y_train = train_label.to_numpy()\n",
    "\n",
    "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
    "y_val = val_label.to_numpy()\n",
    "\n",
    "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
    "y_test = test_label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier using KNNs for estimation of class-conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_list = [10, 20]\n",
    "classifier.KNN(K_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with Gaussian Distribution for All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with GMM with diagonal covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_list = [2, 4, 5, 8, 10, 12]\n",
    "classifier.gmm(Q_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with GMM with full covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_list = [2, 4, 5, 8, 10, 12]\n",
    "classifier.gmm(Q_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train_data.csv\", header=None)\n",
    "train_label = pd.read_csv(\"./train_label.csv\", header=None)\n",
    "\n",
    "val_data = pd.read_csv(\"./val_data.csv\", header=None)\n",
    "val_label = pd.read_csv(\"./val_label.csv\", header=None)\n",
    "\n",
    "test_data = pd.read_csv(\"./test_data.csv\", header=None)\n",
    "test_label = pd.read_csv(\"./test_label.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(train_data.to_numpy(), (-1, 81))\n",
    "y_train = np.reshape(train_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
    "\n",
    "X_val = np.reshape(val_data.to_numpy(), (-1, 81))\n",
    "y_val = np.reshape(val_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
    "\n",
    "X_test = np.reshape(test_data.to_numpy(), (-1, 81))\n",
    "y_test = np.reshape(test_label.to_numpy(dtype=\"int64\"), (-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with KNNs for estimation of class-conditional probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_list = [10, 20]\n",
    "classifier.KNN(K_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with Gaussian Distribution for All Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with GMM with diagonal covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_list = [2, 4, 5, 8, 10, 12]\n",
    "classifier.gmm(Q_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier with GMM with full covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_list = [2, 4, 5, 8, 10, 12]\n",
    "classifier.gmm(Q_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
