{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP-YYyNbImQt"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiFuek1RImQu"
      },
      "source": [
        "# Download the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYOvJTR-ImQv"
      },
      "outputs": [],
      "source": [
        "# Dataset 1a\n",
        "! gdown 1u_VR07Kee92JrhAGq3VeXFR28uoZgxCX\n",
        "! gdown 1IvZk4IvzHVnEWGFqKZoea_OoqEEagLPs\n",
        "! gdown 1UItAFItujkbAo_RMouBnzBOPZ2306J7K\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5FMWLSHImQw"
      },
      "outputs": [],
      "source": [
        "# Dataset 1b\n",
        "! gdown 1iAPQ4tZIN1b7p3InunX5KbFd_8xMczVP\n",
        "! gdown 1BJekqgyr8tf_q_c3RQyPSpZNUwh5Ojhs\n",
        "! gdown 1BGG5CgFE3WClWVQPj4NJe_4jcSJ5PatO\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adlkK-VqImQw"
      },
      "outputs": [],
      "source": [
        "# Dataset 2\n",
        "! gdown 18nytesvrVSgyEApS9HqDBmop6vp5Rx-s\n",
        "! gdown 1aHIU8LzMreWJyn6roXFFwUA9IIs4Rrmy\n",
        "! gdown 1W0pGwuBlXZ8dnoZhvf8rOJD1zaG_8Htb\n",
        "! gdown 1G5yg9ZF9Wtx5JiIVANISlwdgUBC_d5iP\n",
        "! gdown 1ppBq_NSdtbMO6OGCi0I9mXJd5kGH6n_F\n",
        "! gdown 1QmHYtmKFPLL-3TxMWKa5DI4bHcAq6e5A\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1DLu0e7ImQw"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lK5RAhVNImQw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import cholesky\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import cdist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3avQcEqJzyy"
      },
      "source": [
        "# K- Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3foVmLJJzez"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.num_features = self.X_train.shape[1]\n",
        "\n",
        "        # knn\n",
        "        self.num_classes = None\n",
        "        self.train_classes = None\n",
        "        self.val_classes = None\n",
        "        self.test_classes = None\n",
        "\n",
        "        self.init_classes()\n",
        "\n",
        "    def init_classes(self):\n",
        "        unique_classes = np.unique(self.y_train)\n",
        "\n",
        "        self.num_classes = unique_classes.shape[0]\n",
        "\n",
        "        self.train_classes = {label: self.X_train[self.y_train == label] for label in unique_classes}\n",
        "        self.val_classes = {label: self.X_val[self.y_val == label] for label in unique_classes}\n",
        "        self.test_classes = {label: self.X_test[self.y_test == label] for label in unique_classes}\n",
        "\n",
        "    def train(self, K_list):\n",
        "        classification_accuracy = {\n",
        "            \"K\" : [],\n",
        "            \"Training Accuracy\" : [],\n",
        "            \"Validation Accuracy\" : [],\n",
        "            \"Testing Accuracy\" : [],\n",
        "        }\n",
        "\n",
        "        for K in K_list:\n",
        "            # plot the decision boundary if it is 2-dimensional input\n",
        "            if(self.num_features == 2):\n",
        "                x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
        "                y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
        "\n",
        "                X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
        "                X = np.c_[X1.ravel(), X2.ravel()]\n",
        "\n",
        "                Z = np.array([self.predict(K, x) for x in X])\n",
        "                Z = Z.reshape(X1.shape)\n",
        "\n",
        "                plt.figure(figsize=(10, 10))\n",
        "                plt.contourf(X1, X2, Z, alpha=0.4)\n",
        "\n",
        "                for i in range(self.num_classes):\n",
        "                    plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
        "\n",
        "                plt.title(f\"KNN Decision Boundary for K = {K}\")\n",
        "                plt.xlabel(\"X1\")\n",
        "                plt.ylabel(\"X2\")\n",
        "                plt.legend()\n",
        "                plt.savefig(f\"KNN with K = {K}.jpeg\", dpi=300, format=\"jpeg\")\n",
        "                plt.close()\n",
        "\n",
        "            # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_train, self.y_train):\n",
        "                prediction = self.predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Training_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_val, self.y_val):\n",
        "                prediction = self.predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Validation_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_test, self.y_test):\n",
        "                prediction = self.predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Testing Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            classification_accuracy[\"K\"].append(K)\n",
        "            classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
        "            classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
        "            classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
        "\n",
        "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
        "        accuracy_df.to_csv(\"KNN Accuracy.csv\", index=False)\n",
        "\n",
        "    def predict(self, K, origin):\n",
        "        prediction = None\n",
        "        prediction_radius = 1e9\n",
        "\n",
        "        for cls in range(self.num_classes):\n",
        "            distances = np.linalg.norm(self.train_classes[cls] - origin, axis=1)\n",
        "            K_nearest_neighbours = np.argsort(distances)[:K]\n",
        "\n",
        "            smallest_radius = distances[K_nearest_neighbours[-1]]\n",
        "            if(prediction_radius > smallest_radius):\n",
        "                prediction = cls\n",
        "                prediction_radius = smallest_radius\n",
        "\n",
        "        return prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSzXI3_jrosr"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-tpwLccfj6q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, covariance_flag=\"normal\"):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.num_classes = np.unique(y_train).shape[0]\n",
        "        self.num_features = X_train.shape[1]\n",
        "\n",
        "        # Flags\n",
        "        self.covariance_flag = covariance_flag\n",
        "\n",
        "        # Parameters\n",
        "        self.class_priors = None\n",
        "        self.class_means = None\n",
        "        self.class_covariance = None\n",
        "\n",
        "        self.train()\n",
        "\n",
        "    def train(self):\n",
        "        self.class_priors = [np.mean(self.y_train == i) for i in range(self.num_classes)]\n",
        "\n",
        "        self.class_means = [np.mean(self.X_train[self.y_train == i], axis=0) for i in range(self.num_classes)]\n",
        "\n",
        "        if self.covariance_flag == \"same\":\n",
        "            # Compute diagonal covariance matrix assuming independence of features\n",
        "            feature_variances = [np.var(self.X_train[self.y_train == i], axis=0) for i in range(self.num_classes)]\n",
        "            self.class_covariance = np.diag(np.mean(feature_variances, axis=0))\n",
        "        else:\n",
        "            # Compute diagonal covariance matrices for each class\n",
        "            self.class_covariance = [np.diag(np.var(self.X_train[self.y_train == i], axis=0)) for i in range(self.num_classes)]\n",
        "\n",
        "    def predict(self, X):\n",
        "        class_scores = []\n",
        "\n",
        "        for i in range(self.num_classes):\n",
        "            mean = self.class_means[i]\n",
        "            cov = self.class_covariance if self.covariance_flag == \"same\" else self.class_covariance[i]\n",
        "\n",
        "            class_scores.append(multivariate_normal.logpdf(X, mean=mean, cov=cov) + np.log(self.class_priors[i]))\n",
        "\n",
        "        return np.argmax(class_scores, axis=0)\n",
        "\n",
        "    def evaluate(self):\n",
        "        # Table of classification accuracies\n",
        "        accuracy_table = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\", \"Testing Accuracy\"])\n",
        "\n",
        "        # Train the model\n",
        "        self.train()\n",
        "\n",
        "        # Evaluate accuracy\n",
        "        training_accuracy = self.evaluate_accuracy(self.X_train, self.y_train)\n",
        "        validation_accuracy = self.evaluate_accuracy(self.X_val, self.y_val)\n",
        "        testing_accuracy = self.evaluate_accuracy(self.X_test, self.y_test)\n",
        "\n",
        "        accuracy_table = accuracy_table.append({\n",
        "            \"Training Accuracy\": training_accuracy,\n",
        "            \"Validation Accuracy\": validation_accuracy,\n",
        "            \"Testing Accuracy\": testing_accuracy\n",
        "        }, ignore_index=True)\n",
        "\n",
        "        # Generate decision region plot\n",
        "        if self.num_features == 2:\n",
        "            self.plot_decision_regions()\n",
        "\n",
        "        # Save results\n",
        "        self.save_results(accuracy_table, testing_accuracy)\n",
        "\n",
        "        return accuracy_table, training_accuracy, validation_accuracy, testing_accuracy\n",
        "\n",
        "    def evaluate_accuracy(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        return accuracy\n",
        "\n",
        "    def gaussian_pdf(self, x, mean, covariance):\n",
        "        return (1 / np.sqrt(np.linalg.det(covariance))) * np.exp(-0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(covariance)), (x - mean)))\n",
        "\n",
        "    def generate_confusion_matrix(self, X, y):\n",
        "        num_classes = np.unique(y).shape[0]\n",
        "        confusion_matrix = np.zeros((num_classes, num_classes), dtype=\"int64\")\n",
        "\n",
        "        predictions = self.predict(X)\n",
        "\n",
        "        for true_label, predicted_label in zip(y, predictions):\n",
        "            confusion_matrix[true_label, predicted_label] += 1\n",
        "\n",
        "        return confusion_matrix\n",
        "\n",
        "    def plot_decision_regions(self):\n",
        "        if self.num_features == 2:\n",
        "            x_min, x_max = self.X_train[:, 0].min() - 5, self.X_train[:, 0].max() + 5\n",
        "            y_min, y_max = self.X_train[:, 1].min() - 5, self.X_train[:, 1].max() + 5\n",
        "\n",
        "            xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "            positions = np.c_[xx.ravel(), yy.ravel()]\n",
        "            Z = np.array([self.predict(np.array([x])) for x in positions])\n",
        "            Z = Z.reshape(xx.shape)\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.contourf(xx, yy, Z, alpha=0.4)\n",
        "\n",
        "            for i in range(self.num_classes):\n",
        "                X1, X2 = np.meshgrid(np.linspace(self.class_means[i][0] - 10, self.class_means[i][0] + 10, 100),\n",
        "                                    np.linspace(self.class_means[i][1] - 10, self.class_means[i][1] + 10, 100))\n",
        "                positions = np.vstack([X1.ravel(), X2.ravel()])\n",
        "                if self.covariance_flag == \"same\":\n",
        "                    Z = np.array([self.gaussian_pdf(x, self.class_means[i], self.class_covariance) for x in positions.T])\n",
        "                else:\n",
        "                    Z = np.array([self.gaussian_pdf(x, self.class_means[i], self.class_covariance[i]) for x in positions.T])\n",
        "\n",
        "                Z = Z.reshape(X1.shape)\n",
        "\n",
        "                # Plot the Gaussian PDF as level contours\n",
        "                plt.contour(X1, X2, Z, colors=\"grey\", levels=20, alpha=0.7, linewidths=0.6)\n",
        "\n",
        "                # Plot training points\n",
        "                plt.scatter(self.X_train[self.y_train == i][:, 0], self.X_train[self.y_train == i][:, 1],\n",
        "                            s=20, edgecolor=\"k\", label=f\"Training Points - Class {i + 1}\")\n",
        "\n",
        "            plt.xlabel(\"Feature 1\")\n",
        "            plt.ylabel(\"Feature 2\")\n",
        "            plt.title(f\"Naive Bayes Decision Region - {self.covariance_flag}\")\n",
        "\n",
        "            # Ensure equal aspect ratio\n",
        "            plt.axis('equal')\n",
        "\n",
        "            plt.legend()\n",
        "            plt.savefig(f\"Naive_Bayes_Decision_Region_{self.covariance_flag}.jpeg\", dpi=300, format=\"jpeg\")\n",
        "            plt.close()\n",
        "\n",
        "    def save_results(self, accuracy_table, test_accuracy):\n",
        "        accuracy_table.to_csv(f\"NaiveBayes_Accuracy_Table_{self.covariance_flag}.csv\", index=False)\n",
        "        np.savetxt(f\"NaiveBayes_Test_Accuracy_{self.covariance_flag}.txt\", np.array([test_accuracy]), delimiter=\",\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjWOg84ErsXM"
      },
      "source": [
        "# Hypersphere Parzen Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e3JbcsQ5UYq"
      },
      "outputs": [],
      "source": [
        "class HypersphereParzenBayesClassifier:\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, window_size):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.window_size = window_size\n",
        "\n",
        "        self.num_classes = np.unique(y_train).shape[0]\n",
        "        self.num_features = X_train.shape[1]\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for point in X:\n",
        "            # Calculate distances to training points\n",
        "            distances = cdist([point], self.X_train)\n",
        "\n",
        "            # Count points within hypersphere\n",
        "            within_hypersphere = np.sum(distances < self.window_size)\n",
        "\n",
        "            if within_hypersphere == 0:\n",
        "                # No points within hypersphere, assign label based on the first class\n",
        "                prediction = 0\n",
        "            else:\n",
        "                # Find the majority class within hypersphere\n",
        "                majority_class = np.argmax(np.bincount(self.y_train[distances[0] < self.window_size]))\n",
        "\n",
        "                prediction = majority_class\n",
        "\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def evaluate_accuracy(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        return accuracy\n",
        "\n",
        "    def train(self):\n",
        "        self.class_priors = [np.mean(self.y_train == i) for i in range(self.num_classes)]\n",
        "        self.class_centers = [np.mean(self.X_train[self.y_train == i], axis=0) for i in range(self.num_classes)]\n",
        "        self.hypersphere_radii = [self.calculate_hypersphere_radius(self.X_train, self.y_train, i) for i in range(self.num_classes)]\n",
        "\n",
        "    def calculate_hypersphere_radius(self, X, y, class_label):\n",
        "        class_data = X[y == class_label]\n",
        "        max_distance = 0\n",
        "\n",
        "        for i in range(len(class_data)):\n",
        "            distances = cdist(X, [class_data[i]])\n",
        "            within_hypersphere = distances[distances < self.window_size]\n",
        "\n",
        "            if len(within_hypersphere) > 0:\n",
        "                max_distance = max(max_distance, np.max(within_hypersphere))\n",
        "\n",
        "        return max_distance\n",
        "\n",
        "    def generate_confusion_matrix(self, X, y):\n",
        "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "\n",
        "        predictions = self.predict(X)\n",
        "\n",
        "        for i in range(len(y)):\n",
        "            true_label = int(y[i])\n",
        "            predicted_label = int(predictions[i])\n",
        "\n",
        "            confusion_matrix[true_label, predicted_label] += 1\n",
        "\n",
        "        return confusion_matrix\n",
        "\n",
        "\n",
        "    def plot_decision_regions(self, window_size, highlight_best=False):\n",
        "        if self.num_features == 2:\n",
        "            x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
        "            y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
        "\n",
        "            xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "            Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "            Z = Z.reshape(xx.shape)\n",
        "\n",
        "            plt.contourf(xx, yy, Z, alpha=0.4)\n",
        "            plt.scatter(self.X_train[:, 0], self.X_train[:, 1], c=self.y_train, edgecolors='k', marker='o', s=50, linewidth=1, label='Training Data')\n",
        "            plt.xlabel(\"Feature 1\")\n",
        "            plt.ylabel(\"Feature 2\")\n",
        "            plt.title(f\"HypersphereParzenBayes Decision Region Plot (Window Size = {window_size})\")\n",
        "\n",
        "            if highlight_best:\n",
        "                plt.legend()\n",
        "\n",
        "            if (not highlight_best):\n",
        "                plt.savefig(f\"Hypersphere Parzen Bayes with window size = {window_size}.jpeg\", dpi=300, format=\"jpeg\")\n",
        "            else:\n",
        "                plt.savefig(f\"Hypersphere Parzen Bayes Best Model with window size = {window_size}.jpeg\", dpi=300, format=\"jpeg\")\n",
        "\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "    def save_results(self, accuracy_table, test_accuracy, train_conf_matrix, val_conf_matrix, test_conf_matrix):\n",
        "        accuracy_table.to_csv(\"HypersphereParzenBayes_Accuracy_Table.csv\", index=False)\n",
        "        np.savetxt(\"HypersphereParzenBayes_Test_Accuracy.txt\", np.array([test_accuracy]), delimiter=\",\")\n",
        "        np.savetxt(\"HypersphereParzenBayes_Training_Confusion_Matrix.csv\", train_conf_matrix, delimiter=\",\")\n",
        "        np.savetxt(\"HypersphereParzenBayes_Validation_Confusion_Matrix.csv\", val_conf_matrix, delimiter=\",\")\n",
        "        np.savetxt(\"HypersphereParzenBayes_Test_Confusion_Matrix.csv\", test_conf_matrix, delimiter=\",\")\n",
        "\n",
        "    def evaluate(self, w_list):\n",
        "        # Table of classification accuracies\n",
        "        accuracy_table = pd.DataFrame(columns=[\"Window Size\", \"Training Accuracy\", \"Validation Accuracy\", \"Test Accuracy\"])\n",
        "\n",
        "        best_accuracy = 0\n",
        "        best_window_size = None\n",
        "\n",
        "        for window_size in w_list:\n",
        "            self.window_size = window_size\n",
        "\n",
        "            training_accuracy = self.evaluate_accuracy(self.X_train, self.y_train)\n",
        "            validation_accuracy = self.evaluate_accuracy(self.X_val, self.y_val)\n",
        "            test_accuracy = self.evaluate_accuracy(self.X_test, self.y_test)\n",
        "\n",
        "            accuracy_table = accuracy_table.append({\n",
        "                \"Window Size\": window_size,\n",
        "                \"Training Accuracy\": training_accuracy,\n",
        "                \"Validation Accuracy\": validation_accuracy,\n",
        "                \"Test Accuracy\": test_accuracy\n",
        "            }, ignore_index=True)\n",
        "\n",
        "            # Check if this configuration is the best so far\n",
        "            if validation_accuracy > best_accuracy:\n",
        "                best_accuracy = validation_accuracy\n",
        "                best_window_size = window_size\n",
        "\n",
        "            # Plot decision region for the current window size\n",
        "            self.plot_decision_regions(window_size, highlight_best=False)\n",
        "\n",
        "        # Set the best window size\n",
        "        self.window_size = best_window_size\n",
        "\n",
        "        # Test accuracy for the best window size\n",
        "        best_test_accuracy = self.evaluate_accuracy(self.X_test, self.y_test)\n",
        "\n",
        "        # Confusion matrix for training and test data\n",
        "        train_conf_matrix = self.generate_confusion_matrix(self.X_train, self.y_train)\n",
        "        val_conf_matrix = self.generate_confusion_matrix(self.X_val, self.y_val)\n",
        "        test_conf_matrix = self.generate_confusion_matrix(self.X_test, self.y_test)\n",
        "\n",
        "        # Decision region plots for the best window size\n",
        "        self.plot_decision_regions(best_window_size, highlight_best=True)\n",
        "\n",
        "        # Save results\n",
        "        self.save_results(accuracy_table, best_test_accuracy, train_conf_matrix, val_conf_matrix, test_conf_matrix)\n",
        "\n",
        "        return accuracy_table, best_test_accuracy, train_conf_matrix, val_conf_matrix, test_conf_matrix\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# hypersphere_parzen_classifier = HypersphereParzenBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, window_size=0.1)\n",
        "# accuracy_table, test_accuracy, train_conf_matrix, test_conf_matrix = hypersphere_parzen_classifier.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRMTze0W-iGF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"Shaun/DataSet1a/images\")\n",
        "os.makedirs(\"Shaun/DataSet1a/sheets\")\n",
        "os.makedirs(\"Shaun/DataSet1a/texts\")\n",
        "\n",
        "os.makedirs(\"Shaun/DataSet1b/images\")\n",
        "os.makedirs(\"Shaun/DataSet1b/sheets\")\n",
        "os.makedirs(\"Shaun/DataSet1b/texts\")\n",
        "\n",
        "os.makedirs(\"Shaun/DataSet2/images\")\n",
        "os.makedirs(\"Shaun/DataSet2/sheets\")\n",
        "os.makedirs(\"Shaun/DataSet2/texts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IBCsxWeMZPM"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./Train-20.csv\")\n",
        "val_df = pd.read_csv(\"./Val-20.csv\")\n",
        "test_df = pd.read_csv(\"./Test-20.csv\")\n",
        "\n",
        "train_data = train_df[[\"input1\", \"input2\"]]\n",
        "train_label = train_df[\"output\"].astype(int)\n",
        "\n",
        "val_data = val_df[[\"input1\", \"input2\"]]\n",
        "val_label = val_df[\"output\"].astype(int)\n",
        "\n",
        "test_data = test_df[[\"input1\", \"input2\"]]\n",
        "test_label = test_df[\"output\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTso62fsMWj0"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
        "y_train = train_label.to_numpy()\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
        "y_val = val_label.to_numpy()\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
        "y_test = test_label.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyuzmVvxMa6n"
      },
      "outputs": [],
      "source": [
        "# Instantiate the KNN class\n",
        "classifier = KNN(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "K_list = [1, 7, 15]\n",
        "classifier.train(K_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5BOaordgAi4"
      },
      "outputs": [],
      "source": [
        "nb_classifier = NaiveBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, covariance_flag=\"normal\")\n",
        "nb_classifier.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkBdm0byiB5A"
      },
      "outputs": [],
      "source": [
        "nb_classifier = NaiveBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, covariance_flag=\"same\")\n",
        "nb_classifier.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4YCLLtD5eQU"
      },
      "outputs": [],
      "source": [
        "w_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10]\n",
        "hypersphere_parzen_classifier = HypersphereParzenBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, window_size=0.1)\n",
        "hypersphere_parzen_classifier.evaluate(w_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-mmYMjthQsO"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./Train-10.csv\")\n",
        "val_df = pd.read_csv(\"./Val-10.csv\")\n",
        "test_df = pd.read_csv(\"./Test-10.csv\")\n",
        "\n",
        "train_data = train_df[[\"x1\", \"x2\"]]\n",
        "train_label = train_df[\"label\"].astype(int)\n",
        "\n",
        "val_data = val_df[[\"x1\", \"x2\"]]\n",
        "val_label = val_df[\"label\"].astype(int)\n",
        "\n",
        "test_data = test_df[[\"x1\", \"x2\"]]\n",
        "test_label = test_df[\"label\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQX-WxvmhXb6"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
        "y_train = train_label.to_numpy()\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
        "y_val = val_label.to_numpy()\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
        "y_test = test_label.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ccyuqf-hZTy"
      },
      "outputs": [],
      "source": [
        "# Instantiate the KNN class\n",
        "classifier = KNN(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "K_list = [1, 7, 15]\n",
        "classifier.train(K_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBrGjWB1hczF"
      },
      "outputs": [],
      "source": [
        "nb_classifier = NaiveBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, covariance_flag=\"normal\")\n",
        "nb_classifier.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyFpZdeDcXNY"
      },
      "outputs": [],
      "source": [
        "w_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10]\n",
        "hypersphere_parzen_classifier = HypersphereParzenBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, window_size=0.1)\n",
        "hypersphere_parzen_classifier.evaluate(w_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Hh5rmyiJJ3"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"./train_data.csv\", header=None)\n",
        "train_label = pd.read_csv(\"./train_label.csv\", header=None)\n",
        "\n",
        "val_data = pd.read_csv(\"./val_data.csv\", header=None)\n",
        "val_label = pd.read_csv(\"./val_label.csv\", header=None)\n",
        "\n",
        "test_data = pd.read_csv(\"./test_data.csv\", header=None)\n",
        "test_label = pd.read_csv(\"./test_label.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSNuPDyiJa1"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 81))\n",
        "y_train = np.reshape(train_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 81))\n",
        "y_val = np.reshape(val_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 81))\n",
        "y_test = np.reshape(test_label.to_numpy(dtype=\"int64\"), (-1, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F60p7fWiJns"
      },
      "outputs": [],
      "source": [
        "# Instantiate the KNN class\n",
        "classifier = KNN(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "K_list = [1, 7, 15]\n",
        "classifier.train(K_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3gd4tGliWFa"
      },
      "outputs": [],
      "source": [
        "nb_classifier = NaiveBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, covariance_flag=\"normal\")\n",
        "nb_classifier.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R5d4aOFiWTE"
      },
      "outputs": [],
      "source": [
        "w_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10]\n",
        "hypersphere_parzen_classifier = HypersphereParzenBayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, window_size=0.1)\n",
        "hypersphere_parzen_classifier.evaluate(w_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGtTmHIKImQx"
      },
      "source": [
        "# Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGzAuTQMImQx"
      },
      "outputs": [],
      "source": [
        "class BayesClassifier:\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, method, covariance_type = None):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.num_features = self.X_train.shape[1]\n",
        "\n",
        "        # common\n",
        "        self.num_classes = None\n",
        "        self.train_classes = None\n",
        "        self.val_classes = None\n",
        "        self.test_classes = None\n",
        "\n",
        "        # gaussian and gmm\n",
        "        self.mean = None\n",
        "        self.covariance = None\n",
        "\n",
        "        self.prior_probabilities = None\n",
        "\n",
        "        # gmm\n",
        "        self.num_components = None\n",
        "        self.covariance_type = covariance_type\n",
        "\n",
        "        self.responsibilities = None\n",
        "        self.component_probabilities = None\n",
        "        self.component_means = None\n",
        "        self.component_covariances = None\n",
        "\n",
        "        self.best_num_components = None\n",
        "        self.best_responsibilities = None\n",
        "        self.best_component_probabilities = None\n",
        "        self.best_component_means = None\n",
        "        self.best_component_covariances = None\n",
        "\n",
        "        self.init_classes()\n",
        "\n",
        "        if(method == \"knn\"):\n",
        "            pass\n",
        "        elif(method == \"gaussian\" or method == \"gmm\"):\n",
        "            self.init_gaussian()\n",
        "\n",
        "\n",
        "    def gaussian_pdf(self, x, mean, covariance):\n",
        "        return (1 / np.sqrt(np.linalg.det(covariance))) * np.exp(-0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(covariance)), (x - mean)))\n",
        "\n",
        "\n",
        "    def gaussian_pdf_vectorized(self, x, mean, covariance):\n",
        "        n = len(mean)\n",
        "        x_mean = x - mean\n",
        "        inv_cov = np.linalg.inv(covariance)\n",
        "        normalization = 1.0 / np.sqrt((2 * np.pi) ** n * np.linalg.det(covariance))\n",
        "        exponent = -0.5 * np.sum(x_mean.dot(inv_cov) * x_mean, axis=1)\n",
        "        pdf = normalization * np.exp(exponent)\n",
        "        return pdf\n",
        "\n",
        "\n",
        "    def init_classes(self):\n",
        "        unique_classes = np.unique(self.y_train)\n",
        "\n",
        "        self.num_classes = unique_classes.shape[0]\n",
        "\n",
        "        self.train_classes = {label: self.X_train[self.y_train == label] for label in unique_classes}\n",
        "        self.val_classes = {label: self.X_val[self.y_val == label] for label in unique_classes}\n",
        "        self.test_classes = {label: self.X_test[self.y_test == label] for label in unique_classes}\n",
        "\n",
        "        self.prior_probabilities = {label: (self.train_classes[label].shape[0] / self.X_train.shape[0]) for label in unique_classes}\n",
        "\n",
        "    def init_gaussian(self):\n",
        "        for i in range(self.num_classes):\n",
        "            self.mean = {label: np.mean(self.train_classes[label], axis=0) for label in self.train_classes}\n",
        "            self.covariance = {label: np.cov(self.train_classes[label].T) for label in self.train_classes}\n",
        "\n",
        "\n",
        "    def init_gmm(self):\n",
        "        # K-means clustering to identify num_componenent clusters in each class\n",
        "        max_iters = 200\n",
        "\n",
        "        components = {}\n",
        "        for i in range(self.num_classes):\n",
        "            components[i] = {}\n",
        "\n",
        "        for i in range(self.num_classes):\n",
        "            n = self.train_classes[i].shape[0]\n",
        "            centroids = self.train_classes[i][np.random.choice(n, self.num_components, replace=False)]\n",
        "\n",
        "            for _ in range(max_iters):\n",
        "                # Assign each data point to the nearest cluster\n",
        "                distances = np.linalg.norm(self.train_classes[i][:, np.newaxis] - centroids, axis=2)\n",
        "                labels = np.argmin(distances, axis=1)\n",
        "\n",
        "                # Update cluster centroids\n",
        "                new_centroids = np.array([self.train_classes[i][labels == k].mean(axis=0) if np.sum(labels == k) > 0 else centroids[k] for k in range(self.num_components)])\n",
        "\n",
        "                # Check for convergence\n",
        "                if np.all(new_centroids == centroids):\n",
        "                    break\n",
        "\n",
        "                centroids = new_centroids\n",
        "\n",
        "            # assign the samples to the clusters based on nearest centroid\n",
        "            distances = np.linalg.norm(self.train_classes[i][:, np.newaxis] - centroids, axis=2)\n",
        "            labels = np.argmin(distances, axis=1)\n",
        "            for sample, label in zip(self.train_classes[i], labels):\n",
        "                if(label not in components[i]):\n",
        "                    components[i][label] = []\n",
        "                components[i][label].append(sample)\n",
        "\n",
        "            for label in components[i]:\n",
        "                components[i][label] = np.vstack(components[i][label])\n",
        "\n",
        "        # initialize the parameters of the GMM\n",
        "        self.component_means = {}\n",
        "        self.component_covariances = {}\n",
        "        self.component_probabilities = {}\n",
        "\n",
        "        for i in range(self.num_classes):\n",
        "            self.component_means[i] = {}\n",
        "            self.component_covariances[i] = {}\n",
        "            self.component_probabilities[i] = {}\n",
        "\n",
        "            for label in components[i]:\n",
        "                self.component_means[i][label] = np.mean(components[i][label], axis=0)\n",
        "                self.component_covariances[i][label] = np.cov(components[i][label].T)\n",
        "                if(self.covariance_type == \"diagonal\"):\n",
        "                    self.component_covariances[i][label] = np.diag(np.diag(self.component_covariances[i][label]))\n",
        "                self.component_probabilities[i][label] = components[i][label].shape[0] / self.train_classes[i].shape[0]\n",
        "\n",
        "        self.responsibilities = {}\n",
        "        for i in range(self.num_classes):\n",
        "            self.responsibilities[i] = np.zeros((self.train_classes[i].shape[0], self.num_components))\n",
        "\n",
        "        # EM algorithm\n",
        "        max_iters = 200\n",
        "        for _ in range(max_iters):\n",
        "            # E-step\n",
        "            for i in range(self.num_classes):\n",
        "                for label in components[i]:\n",
        "                    self.responsibilities[i][:, label] = self.component_probabilities[i][label] * self.gaussian_pdf_vectorized(self.train_classes[i], self.component_means[i][label], self.component_covariances[i][label])\n",
        "                self.responsibilities[i] /= np.sum(self.responsibilities[i], axis=1, keepdims=True)\n",
        "\n",
        "            # M-step\n",
        "            for i in range(self.num_classes):\n",
        "                for label in components[i]:\n",
        "                    self.component_means[i][label] = np.sum(self.responsibilities[i][:, label][:, np.newaxis] * self.train_classes[i], axis=0) / np.sum(self.responsibilities[i][:, label])\n",
        "                    self.component_covariances[i][label] = np.dot((self.responsibilities[i][:, label][:, np.newaxis] * (self.train_classes[i] - self.component_means[i][label])).T, (self.train_classes[i] - self.component_means[i][label])) / np.sum(self.responsibilities[i][:, label])\n",
        "                    if(self.covariance_type == \"diagonal\"):\n",
        "                        self.component_covariances[i][label] = np.diag(np.diag(self.component_covariances[i][label]))\n",
        "                    self.component_probabilities[i][label] = np.sum(self.responsibilities[i][:, label]) / self.train_classes[i].shape[0]\n",
        "\n",
        "\n",
        "    def KNN_predict(self, K, origin):\n",
        "        prediction = None\n",
        "        prediction_radius = 1e9\n",
        "\n",
        "        for cls in range(self.num_classes):\n",
        "            distances = np.linalg.norm(self.train_classes[cls] - origin, axis=1)\n",
        "            K_nearest_neighbours = np.argsort(distances)[:K]\n",
        "\n",
        "            smallest_radius = distances[K_nearest_neighbours[-1]]\n",
        "            if(prediction_radius > smallest_radius):\n",
        "                prediction = cls\n",
        "                prediction_radius = smallest_radius\n",
        "\n",
        "        return prediction\n",
        "\n",
        "\n",
        "    def KNN(self, K_list):\n",
        "        classification_accuracy = {\n",
        "            \"K\" : [],\n",
        "            \"Training Accuracy\" : [],\n",
        "            \"Validation Accuracy\" : [],\n",
        "            \"Testing Accuracy\" : [],\n",
        "        }\n",
        "\n",
        "        for K in K_list:\n",
        "            # plot the decision boundary if it is 2-dimensional input\n",
        "            if(self.num_features == 2):\n",
        "                x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
        "                y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
        "\n",
        "                X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
        "                X = np.c_[X1.ravel(), X2.ravel()]\n",
        "\n",
        "                Z = np.array([self.KNN_predict(K, x) for x in X])\n",
        "                Z = Z.reshape(X1.shape)\n",
        "\n",
        "                plt.figure(figsize=(10, 10))\n",
        "                plt.contourf(X1, X2, Z, alpha=0.4)\n",
        "\n",
        "                for i in range(self.num_classes):\n",
        "                    plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
        "\n",
        "                plt.title(f\"KNN Decision Boundary for K = {K}\")\n",
        "                plt.xlabel(\"X1\")\n",
        "                plt.ylabel(\"X2\")\n",
        "                plt.legend()\n",
        "\n",
        "                plt.savefig(f\"Bayes Classifier using KNN with K = {K}.jpeg\", dpi=300, format=\"jpeg\")\n",
        "                plt.close()\n",
        "\n",
        "            # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_train, self.y_train):\n",
        "                prediction = self.KNN_predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Training_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_val, self.y_val):\n",
        "                prediction = self.KNN_predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Validation_Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_test, self.y_test):\n",
        "                prediction = self.KNN_predict(K, X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"KNN_Testing Confusion_Matrix(K={K}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            classification_accuracy[\"K\"].append(K)\n",
        "            classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
        "            classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
        "            classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
        "\n",
        "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
        "        accuracy_df.to_csv(\"KNN Accuracy.csv\", index=False)\n",
        "\n",
        "\n",
        "    def gaussian_predict(self, x):\n",
        "        probabilities = np.zeros(self.num_classes)\n",
        "\n",
        "        for cls in range(self.num_classes):\n",
        "            probabilities[cls] = self.prior_probabilities[cls] * self.gaussian_pdf(x, self.mean[cls], self.covariance[cls])\n",
        "\n",
        "        return np.argmax(probabilities)\n",
        "\n",
        "\n",
        "    def gaussian(self):\n",
        "        # plot the decision boundary and level curves if it is 2-dimensional input\n",
        "        if(self.num_features == 2):\n",
        "            x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
        "            y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
        "\n",
        "            X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
        "\n",
        "            Z = np.array([self.gaussian_predict(x) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
        "            Z = Z.reshape(X1.shape)\n",
        "\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.contourf(X1, X2, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "            for i in range(self.num_classes):\n",
        "                X1, X2 = np.meshgrid(np.linspace(self.mean[i][0] - 10, self.mean[i][0] + 10, 100), np.linspace(self.mean[i][1] - 10, self.mean[i][1] + 10, 100))\n",
        "                Z = np.array([self.gaussian_pdf(x, self.mean[i], self.covariance[i]) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
        "                Z = Z.reshape(X1.shape)\n",
        "                plt.contour(X1, X2, Z, colors=\"grey\", levels=20, alpha=0.7, linewidths=0.6)\n",
        "\n",
        "            for i in range(self.num_classes):\n",
        "                plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
        "\n",
        "            plt.title(f\"Gaussian Decision Boundary and Level Curves\")\n",
        "            plt.xlabel(\"X1\")\n",
        "            plt.ylabel(\"X2\")\n",
        "            plt.legend()\n",
        "\n",
        "            plt.savefig(f\"Bayes Classifier using Gaussian.png\", dpi=300, format=\"png\")\n",
        "            plt.close()\n",
        "\n",
        "        classification_accuracy = {\n",
        "            \"Training Accuracy\" : [],\n",
        "            \"Validation Accuracy\" : [],\n",
        "            \"Testing Accuracy\" : [],\n",
        "        }\n",
        "\n",
        "        # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
        "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "        for X, y in zip(self.X_train, self.y_train):\n",
        "            prediction = self.gaussian_predict(X)\n",
        "            confusion_matrix[y, prediction] += 1\n",
        "\n",
        "        training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "        np.savetxt(\"Gaussian_Training_Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "        for X, y in zip(self.X_val, self.y_val):\n",
        "            prediction = self.gaussian_predict(X)\n",
        "            confusion_matrix[y, prediction] += 1\n",
        "\n",
        "        validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "        np.savetxt(\"Gaussian_Validation_Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "        confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "        for X, y in zip(self.X_test, self.y_test):\n",
        "            prediction = self.gaussian_predict(X)\n",
        "            confusion_matrix[y, prediction] += 1\n",
        "\n",
        "        testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "        np.savetxt(\"Gaussian_Testing Confusion_Matrix.csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "        classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
        "        classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
        "        classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
        "\n",
        "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
        "        accuracy_df.to_csv(\"Gaussian Accuracy.csv\", index=False)\n",
        "\n",
        "\n",
        "    def gmm_predict(self, x):\n",
        "        probabilities = np.zeros(self.num_classes)\n",
        "\n",
        "        for cls in range(self.num_classes):\n",
        "            for label in self.component_means[cls]:\n",
        "                probabilities[cls] += self.component_probabilities[cls][label] * self.gaussian_pdf(x, self.component_means[cls][label], self.component_covariances[cls][label])\n",
        "\n",
        "        return np.argmax(probabilities)\n",
        "\n",
        "\n",
        "    def gmm(self, Q_list):\n",
        "        # plot the decision boundary and level curves if it is 2-dimensional input\n",
        "        classification_accuracy = {\n",
        "            \"Number of Components\" : [],\n",
        "            \"Training Accuracy\" : [],\n",
        "            \"Validation Accuracy\" : [],\n",
        "            \"Testing Accuracy\" : [],\n",
        "        }\n",
        "\n",
        "        best_val_accuracy = 0\n",
        "        for Q in Q_list:\n",
        "            self.num_components = Q\n",
        "            self.init_gmm()\n",
        "            if(self.num_features == 2):\n",
        "                x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
        "                y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
        "\n",
        "                X1, X2 = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
        "\n",
        "                Z = np.array([self.gmm_predict(x) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
        "                Z = Z.reshape(X1.shape)\n",
        "\n",
        "                plt.figure(figsize=(10, 10))\n",
        "                plt.contourf(X1, X2, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "                for i in range(self.num_classes):\n",
        "                    for label in self.component_means[i]:\n",
        "                        X1, X2 = np.meshgrid(np.linspace(self.component_means[i][label][0] - 10, self.component_means[i][label][0] + 10, 100), np.linspace(self.component_means[i][label][1] - 10, self.component_means[i][label][1] + 10, 100))\n",
        "                        Z = np.array([self.gaussian_pdf(x, self.component_means[i][label], self.component_covariances[i][label]) for x in np.c_[X1.ravel(), X2.ravel()]])\n",
        "                        Z = Z.reshape(X1.shape)\n",
        "                        plt.contour(X1, X2, Z, colors=\"grey\", levels=20, alpha=0.7, linewidths=0.6)\n",
        "\n",
        "                for i in range(self.num_classes):\n",
        "                    plt.scatter(self.train_classes[i][:, 0], self.train_classes[i][:, 1], s=20, edgecolor=\"k\", label=f\"Training Points- Class {i+1}\")\n",
        "\n",
        "                plt.title(f\"GMM Decision Boundary and Level Curves\\nQ={Q}\")\n",
        "                plt.xlabel(\"X1\")\n",
        "                plt.ylabel(\"X2\")\n",
        "                plt.legend()\n",
        "\n",
        "                plt.savefig(f\"Bayes Classifier using GMM(Q={Q}).png\", dpi=300, format=\"png\")\n",
        "                plt.close()\n",
        "\n",
        "            # generate confusion matrix and calculate the accuracy for training, validation and testing data and store them in a csv file\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_train, self.y_train):\n",
        "                prediction = self.gmm_predict(X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            training_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"GMM_Training_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_val, self.y_val):\n",
        "                prediction = self.gmm_predict(X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            validation_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"GMM_Validation_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            confusion_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int64\")\n",
        "            for X, y in zip(self.X_test, self.y_test):\n",
        "                prediction = self.gmm_predict(X)\n",
        "                confusion_matrix[y, prediction] += 1\n",
        "\n",
        "            testing_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "            np.savetxt(f\"GMM_Testing_Confusion_Matrix(Q={Q}).csv\", confusion_matrix, delimiter=\",\")\n",
        "\n",
        "            if(best_val_accuracy < validation_accuracy):\n",
        "                best_val_accuracy = validation_accuracy\n",
        "                self.best_num_components = self.num_components\n",
        "                self.best_responsibilities = self.responsibilities\n",
        "                self.best_component_probabilities = self.component_probabilities\n",
        "                self.best_component_means = self.component_means\n",
        "                self.best_component_covariances = self.component_covariances\n",
        "\n",
        "            classification_accuracy[\"Number of Components\"].append(Q)\n",
        "            classification_accuracy[\"Training Accuracy\"].append(training_accuracy)\n",
        "            classification_accuracy[\"Validation Accuracy\"].append(validation_accuracy)\n",
        "            classification_accuracy[\"Testing Accuracy\"].append(testing_accuracy)\n",
        "\n",
        "        accuracy_df = pd.DataFrame(classification_accuracy)\n",
        "        accuracy_df.to_csv(\"GMM Accuracy.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7mvkn7nImQy"
      },
      "source": [
        "# Dataset 1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TatFuKUkImQy"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./Train-20.csv\")\n",
        "val_df = pd.read_csv(\"./Val-20.csv\")\n",
        "test_df = pd.read_csv(\"./Test-20.csv\")\n",
        "\n",
        "train_data = train_df[[\"input1\", \"input2\"]]\n",
        "train_label = train_df[\"output\"].astype(int)\n",
        "\n",
        "val_data = val_df[[\"input1\", \"input2\"]]\n",
        "val_label = val_df[\"output\"].astype(int)\n",
        "\n",
        "test_data = test_df[[\"input1\", \"input2\"]]\n",
        "test_label = test_df[\"output\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzgDtC4QImQy"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
        "y_train = train_label.to_numpy()\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
        "y_val = val_label.to_numpy()\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
        "y_test = test_label.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brz0hiOVImQy"
      },
      "source": [
        "## Bayes Classifier using KNNs for estimation of class-conditional probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgNogiaYImQy"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkF14IORImQy"
      },
      "outputs": [],
      "source": [
        "K_list = [10, 20]\n",
        "classifier.KNN(K_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lumLIqYqImQz"
      },
      "source": [
        "# Dataset 1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fG98g2toImQz"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './Train-10.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/niveath/Desktop/Computer Science at IITM/Semester 5/CS5691/Assignments/Assignment 2/Team20_A2_Code/Team20_A2_Code.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niveath/Desktop/Computer%20Science%20at%20IITM/Semester%205/CS5691/Assignments/Assignment%202/Team20_A2_Code/Team20_A2_Code.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./Train-10.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niveath/Desktop/Computer%20Science%20at%20IITM/Semester%205/CS5691/Assignments/Assignment%202/Team20_A2_Code/Team20_A2_Code.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m val_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./Val-10.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niveath/Desktop/Computer%20Science%20at%20IITM/Semester%205/CS5691/Assignments/Assignment%202/Team20_A2_Code/Team20_A2_Code.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./Test-10.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Train-10.csv'"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"./Train-10.csv\")\n",
        "val_df = pd.read_csv(\"./Val-10.csv\")\n",
        "test_df = pd.read_csv(\"./Test-10.csv\")\n",
        "\n",
        "train_data = train_df[[\"x1\", \"x2\"]]\n",
        "train_label = train_df[\"label\"].astype(int)\n",
        "\n",
        "val_data = val_df[[\"x1\", \"x2\"]]\n",
        "val_label = val_df[\"label\"].astype(int)\n",
        "\n",
        "test_data = test_df[[\"x1\", \"x2\"]]\n",
        "test_label = test_df[\"label\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkycvvVmImQz"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 2))\n",
        "y_train = train_label.to_numpy()\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 2))\n",
        "y_val = val_label.to_numpy()\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 2))\n",
        "y_test = test_label.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkX9aLsxImQz"
      },
      "source": [
        "## Bayes Classifier using KNNs for estimation of class-conditional probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7CLbTXJImQz"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz35H4sWImQz"
      },
      "outputs": [],
      "source": [
        "K_list = [10, 20]\n",
        "classifier.KNN(K_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEd2WnHGImQz"
      },
      "source": [
        "## Bayes Classifier with Gaussian Distribution for All Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtW8Du_GImQz"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gaussian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGxcOaZ-ImQz"
      },
      "outputs": [],
      "source": [
        "classifier.gaussian()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkuOMlpwImQz"
      },
      "source": [
        "## Bayes Classifier with GMM with diagonal covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHBzyM0yImQz"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"diagonal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF3jX1uFf-xV"
      },
      "outputs": [],
      "source": [
        "Q_list = [2, 4, 5, 8, 10, 12]\n",
        "classifier.gmm(Q_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7psBN-0IImQ0"
      },
      "source": [
        "## Bayes Classifier with GMM with full covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k4WyyEoImQ0"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", 5, \"full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCMwL8JrImQ0"
      },
      "outputs": [],
      "source": [
        "Q_list = [2, 4, 5, 8, 10, 12]\n",
        "classifier.gmm(Q_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNhcPZbXImQ0"
      },
      "source": [
        "# Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CVNedq5ImQ0"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"./train_data.csv\", header=None)\n",
        "train_label = pd.read_csv(\"./train_label.csv\", header=None)\n",
        "\n",
        "val_data = pd.read_csv(\"./val_data.csv\", header=None)\n",
        "val_label = pd.read_csv(\"./val_label.csv\", header=None)\n",
        "\n",
        "test_data = pd.read_csv(\"./test_data.csv\", header=None)\n",
        "test_label = pd.read_csv(\"./test_label.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKTsY3w9ImQ0"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(train_data.to_numpy(), (-1, 81))\n",
        "y_train = np.reshape(train_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
        "\n",
        "X_val = np.reshape(val_data.to_numpy(), (-1, 81))\n",
        "y_val = np.reshape(val_label.to_numpy(dtype=\"int64\"), (-1, ))\n",
        "\n",
        "X_test = np.reshape(test_data.to_numpy(), (-1, 81))\n",
        "y_test = np.reshape(test_label.to_numpy(dtype=\"int64\"), (-1, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVqdwEsGImQ0"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"knn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFkpukJ9ImQ0"
      },
      "outputs": [],
      "source": [
        "K_list = [10, 20]\n",
        "classifier.KNN(K_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJOcco2IImQ0"
      },
      "source": [
        "## Bayes Classifier with Gaussian Distribution for All Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukmAi3qsImQ0"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gaussian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LRO0EwZImQ0"
      },
      "outputs": [],
      "source": [
        "classifier.gaussian()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTZ2lbaQImQ0"
      },
      "source": [
        "## Bayes Classifier with GMM with diagonal covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65qygaOEImQ1"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"diagonal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyJaI97wImQ1"
      },
      "outputs": [],
      "source": [
        "Q_list = [2, 4, 5, 8, 10, 12]\n",
        "classifier.gmm(Q_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI7JKT00ImQ1"
      },
      "source": [
        "## Bayes Classifier with GMM with full covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilq8Pb9xImQ1"
      },
      "outputs": [],
      "source": [
        "classifier = BayesClassifier(X_train, y_train, X_val, y_val, X_test, y_test, \"gmm\", \"full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YHfIgZ1ImQ2"
      },
      "outputs": [],
      "source": [
        "Q_list = [2, 4, 5, 8, 10, 12]\n",
        "classifier.gmm(Q_list)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E3avQcEqJzyy",
        "PSzXI3_jrosr",
        "VjWOg84ErsXM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
